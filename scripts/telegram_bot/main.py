# Standard Library
import json
import os
import logging
import re
import sys
import urllib.parse  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ URL

# Telegram Core
from telegram import (
    Update,
    InlineQueryResultArticle,
    InputTextMessageContent,
    MenuButtonWebApp,
    WebAppInfo,
    BotCommand,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
    InlineQueryResultsButton,  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è "–≥–æ—Ä—è—á–µ–π –∫–Ω–æ–ø–∫–∏"
    error
)

# Telegram Extensions
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    InlineQueryHandler,
    CallbackQueryHandler,
    filters,
    CallbackContext,
)


WELCOME_MESSAGES = {
    "en": (
        "‚ú® Welcome to Dhamma Gift Bot!\n\n"
        "‚ùì <b>How to use:</b>\n\n"
        "üí¨ <b>Call me in any chat or group:</b>\n"
        "‚å®Ô∏è Type @dgift_bot or @dhammagift_bot and start typing a word to search or sutta reference (e.g. <code>sn12.2</code>)\n\n"
        "üí° Suggestions will appear for Pali words and sutta references\n\n"
        "ü§ì You can use Velthuis transliteration for diacritics: <code>.t .d .n ~n aa ii uu</code> ‚Üí <code>·π≠ ·∏ç ·πá √± ƒÅ ƒ´ ≈´</code>\n\n"
        "üí¨ <b>In this private chat:</b>\n"
        "Simply send me a word or reference (e.g. <code>saariputta</code> or <code>mn10</code>)\n\n\n"
        "Following commands available:\n"
        "/start - this message\n"
        "/extra - Mini App links\n"
        "/help - Dhamma.gift help will be here\n\n"
        "Change Bots language üëá –ò–∑–º–µ–Ω–∏—Ç—å —è–∑—ã–∫ \n"
    ),
    "ru": (
        "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ Dhamma Gift Bot!\n\n"
        "üîç <b>–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</b>\n\n"
        "üí¨ <b>–í—ã –º–æ–∂–µ—Ç–µ –≤—ã–∑–≤–∞—Ç—å –º–µ–Ω—è –≤ –ª—é–±–æ–º —á–∞—Ç–µ –∏–ª–∏ –≥—Ä—É–ø–ø–µ:</b>\n"
        "‚å®Ô∏è –ù–∞–ø–∏—à–∏—Ç–µ @dgift_bot –∏–ª–∏ @dhammagift_bot –∏ –Ω–∞—á–Ω–∏—Ç–µ –ø–µ—á–∞—Ç–∞—Ç—å —Å–ª–æ–≤–æ –∏–ª–∏ –Ω–æ–º–µ—Ä —Å—É—Ç—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, <code>sn12.2</code>)\n"
        "üí° –Ø –ø—Ä–µ–¥–ª–æ–∂—É –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–∞–ª–∏–π—Å–∫–∏—Ö —Å–ª–æ–≤ –∏ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—É—Ç—Ç—ã\n\n"
        "ü§ì –¢–∞–∫–∂–µ –í—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é Velthuis –¥–ª—è –¥–∏–∞–∫—Ä–∏—Ç–∏–∫–∏: <code>.t .d .n ~n aa ii uu</code> ‚Üí <code>·π≠ ·∏ç ·πá √± ƒÅ ƒ´ ≈´</code>\n\n"
        "üí¨ <b>–í —ç—Ç–æ–º –ª–∏—á–Ω–æ–º —á–∞—Ç–µ:</b>\n"
        "–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Å–ª–æ–≤–æ –∏–ª–∏ –Ω–æ–º–µ—Ä —Å—É—Ç—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, <code>saariputta</code> –∏–ª–∏ <code>mn10</code>)\n\n\n"
        "–î–æ—Å—Ç—É–ø–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –∫–æ–º–∞–Ω–¥—ã:\n"
        "/start - —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ\n"
        "/extra - —Å—Å—ã–ª–∫–∏ –Ω–∞ Mini Apps\n"
        "/help - –∑–¥–µ—Å—å –±—É–¥–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Dhamma.gift\n\n"
        "–ò–∑–º–µ–Ω–∏—Ç—å —è–∑—ã–∫ –ë–æ—Ç–∞ üëá Change Language\n"

    )
}

EXTRA_MESSAGES = {
    "ru": (
        "–ú–∏–Ω–∏ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –†—É—Å—Å–∫–æ–º. –í—ã –º–æ–∂–µ—Ç–µ –∑–∞–∫—Ä–µ–ø–∏—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞:\n\n"
        "üîé –ü–æ–∏—Å–∫\n"
        "http://t.me/dgift_bot/find\n"
        "üìñ –ß—Ç–µ–Ω–∏–µ\n"
        "http://t.me/dgift_bot/read\n"
        "üåê –°–ª–æ–≤–∞—Ä—å\n"
        "http://t.me/dgift_bot/dict\n\n"
    ),
    "en": (
        "Mini Applications in English. You may want to pin this message for quick access:\n\n"
        "üîé Search\n"
        "http://t.me/dhammagift_bot/find\n"
        "üìñ Read\n"
        "http://t.me/dhammagift_bot/read\n"
        "üåê Dictionary\n"
        "http://t.me/dhammagift_bot/dict\n\n"
    )
}

# === –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞ ===
config_path = sys.argv[1] if len(sys.argv) > 1 else "config.json"
with open(config_path, "r") as f:
    config = json.load(f)

bot_name = config.get("NAME", "default_bot")
TOKEN = config.get("TOKEN", "")
if not TOKEN:
    raise ValueError(f"Token not found in {config_path}")

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
class TelegramTokenFilter(logging.Formatter):
    """–§–æ—Ä–º–∞—Ç—Ç–µ—Ä –¥–ª—è –º–∞—Å–∫–∏—Ä–æ–≤–∫–∏ Telegram bot —Ç–æ–∫–µ–Ω–æ–≤ –≤ –ª–æ–≥–∞—Ö"""
    @staticmethod
    def _mask_token(text: str) -> str:
        return re.sub(
            r'(https?://api\.telegram\.org)/bot[^/]+/',
            r'\1/botTOKEN/',
            text,
            flags=re.IGNORECASE
        )

    def format(self, record):
        original = super().format(record)
        return self._mask_token(original)

# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
file_handler = logging.FileHandler(f"{bot_name}.log")
stream_handler = logging.StreamHandler()
formatter = TelegramTokenFilter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
file_handler.setFormatter(formatter)
stream_handler.setFormatter(formatter)

logging.basicConfig(
    level=logging.INFO,
    handlers=[file_handler, stream_handler],
)
logger = logging.getLogger(__name__)


# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ===
USER_DATA_FILE = f"user_data_{bot_name}.json"
DEFAULT_LANG = "en"

# === –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å JSON-—Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º ===
def load_user_data() -> dict:
    if not os.path.exists(USER_DATA_FILE):
        return {}
    try:
        with open(USER_DATA_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ user_data: {e}")
        return {}

def save_user_data(user_id: int, key: str, value: str):
    try:
        data = load_user_data()
        user_id_str = str(user_id)
        if user_id_str not in data:
            data[user_id_str] = {}
        data[user_id_str][key] = value
        with open(USER_DATA_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è user_data: {e}")

def get_user_lang(user_id: int) -> str:
    data = load_user_data()
    return data.get(str(user_id), {}).get("lang", DEFAULT_LANG)

def get_user_share_lang(user_id: int) -> str:
    data = load_user_data()
    return data.get(str(user_id), {}).get("share_lang", get_user_lang(user_id) or DEFAULT_LANG)

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ ===
def normalize(text: str) -> str:
    if not text:
        return text
    if not hasattr(normalize, "cache"):
        normalize.cache = {}
    if text in normalize.cache:
        return normalize.cache[text]
    
    text_lower = text.lower()
    replacements = [
        ("aa", "a"), ("ii", "i"), ("uu", "u"),
        ('"n', "n"), ("~n", "n"),
        (".t", "t"), (".d", "d"), (".n", "n"),
        (".m", "m"), (".l", "l"), (".h", "h")
    ]
    for pattern, repl in replacements:
        text_lower = text_lower.replace(pattern, repl)
    
    result = (
        text_lower.replace("·πÅ", "m").replace("·πÉ", "m")
        .replace("·π≠", "t").replace("·∏ç", "d")
        .replace("·πá", "n").replace("·πÖ", "n")
        .replace("√±", "n").replace("ƒÅ", "a")
        .replace("ƒ´", "i").replace("≈´", "u")
        .replace(".", " ")
    )
    normalize.cache[text] = result
    return result
    
def autocomplete(prefix: str, max_results: int = 29) -> list[str]:
    try:
        if not hasattr(autocomplete, "word_data"):
            autocomplete.word_data = load_words()
        normalized_dict = autocomplete.word_data.get("normalized_dict", {})
        prefix_n = normalize(prefix)
        
        starts_with = []
        for norm_word, orig_words in normalized_dict.items():
            if norm_word.startswith(prefix_n):
                starts_with.extend(orig_words)
        
        contains = []
        for norm_word, orig_words in normalized_dict.items():
            if prefix_n in norm_word and not norm_word.startswith(prefix_n):
                contains.extend(orig_words)
        
        starts_with = list(dict.fromkeys(starts_with))
        contains = list(dict.fromkeys(contains))
        suggestions = (sorted(starts_with, key=lambda x: normalize(x)) + sorted(contains, key=lambda x: normalize(x)))[:max_results]
        return suggestions
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç–∞: {e}")
        return []

def load_words():
    try:
        path = os.path.join("assets", "sutta_words.txt")
        with open(path, "r", encoding="utf-8") as f:
            words = [line.strip() for line in f if line.strip()]
            normalized_dict = {}
            for word in words:
                norm_word = normalize(word)
                if norm_word not in normalized_dict:
                    normalized_dict[norm_word] = []
                normalized_dict[norm_word].append(word)
            return {"original_words": words, "normalized_dict": normalized_dict}
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ª–æ–≤–∞—Ä—è: {e}")
        return {"original_words": [], "normalized_dict": {}}

WORDS = load_words().get("original_words", [])

# === –ö–õ–ê–í–ò–ê–¢–£–†–´ (—Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º) ===
def create_keyboard(query: str, lang: str = "en", is_inline: bool = False) -> InlineKeyboardMarkup:
    path = "ru/" if lang == "ru" else ""
    encoded_q = urllib.parse.quote_plus(query)
    search_url = f"https://f.dhamma.gift/{path}?p=-kn&q={encoded_q}"
    dict_url = f"https://dict.dhamma.gift/{path}search_html?q={encoded_q}"

    label_dict = "üìò –°–ª–æ–≤–∞—Ä—å" if lang == "ru" else "üìò Dictionary"
    # –û–±–Ω–æ–≤–ª–µ–Ω–æ: –ß–∏—Ç–∞—Ç—å –Ω–∞...
    label_site = f"{'–ß–∏—Ç–∞—Ç—å –Ω–∞' if lang == 'ru' else 'Read at'} üîé Dhamma.gift {'Ru' if lang == 'ru' else 'En'}"
    # –û–±–Ω–æ–≤–ª–µ–Ω–æ: –Ø–∑—ã–∫ Ru/En
    toggle_label = "–Ø–∑—ã–∫ Ru/En" if lang == "ru" else "Lang En/Ru"

    callback_prefix = "inline_" if is_inline else ""
    keyboard = [
        [
            InlineKeyboardButton(text=toggle_label, callback_data=f"{callback_prefix}toggle_lang:{lang}:{query}"),
            InlineKeyboardButton(text=label_dict, url=dict_url),
        ],
        [InlineKeyboardButton(text=label_site, url=search_url)]
    ]
    return InlineKeyboardMarkup(keyboard)

def format_message_with_links(text: str, query: str, lang: str = "en") -> str:
    path = "ru/" if lang == "ru" else ""
    encoded_q = urllib.parse.quote_plus(query)
    search_url = f"https://f.dhamma.gift/{path}?p=-kn&q={encoded_q}"
    dict_url = f"https://dict.dhamma.gift/{path}search_html?q={encoded_q}"
    label_dict = "üìò –°–ª–æ–≤–∞—Ä—å" if lang == "ru" else "üìò Dictionary"
    return f"\n{text}\n\nüîé <a href='{search_url}'>Dhamma.gift</a> | <a href='{dict_url}'>{label_dict}</a>"
    
async def set_menu_button(update: Update, lang: str):
    user_id = update.effective_user.id
    button_text = "DG ru" if lang == "ru" else "DG en"
    button_url = f"https://f.dhamma.gift/{'ru/' if lang == 'ru' else ''}?source=pwa"
    menu_button = MenuButtonWebApp(text=button_text, web_app=WebAppInfo(url=button_url))
    try:
        await update.get_bot().set_chat_menu_button(chat_id=user_id, menu_button=menu_button)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∫–Ω–æ–ø–∫–∏ –º–µ–Ω—é: {e}")

async def start(update: Update, context: CallbackContext):
    user = update.effective_user
    user_lang = get_user_lang(user.id) or 'en'
    keyboard = [[InlineKeyboardButton("–†—É—Å—Å–∫–∏–π" if user_lang == 'en' else "English", callback_data=f"lang_set:{user_lang}")]]
    await update.message.reply_text(WELCOME_MESSAGES[user_lang], reply_markup=InlineKeyboardMarkup(keyboard), parse_mode="HTML", disable_web_page_preview=True)
    await set_menu_button(update, user_lang)

async def handle_language_selection(update: Update, context: CallbackContext):
    query = update.callback_query
    await query.answer()
    user_id = query.from_user.id
    current_lang = query.data.split(':')[1]
    new_lang = 'ru' if current_lang == 'en' else 'en'
    save_user_data(user_id, 'lang', new_lang)
    save_user_data(user_id, 'share_lang', new_lang)
    keyboard = [[InlineKeyboardButton("–†—É—Å—Å–∫–∏–π" if new_lang == 'en' else "English", callback_data=f"lang_set:{new_lang}")]]
    await query.edit_message_text(text=WELCOME_MESSAGES[new_lang], reply_markup=InlineKeyboardMarkup(keyboard), parse_mode="HTML")
    await set_menu_button(update, new_lang)

async def extra_command(update: Update, context: CallbackContext):
    lang = get_user_lang(update.effective_user.id) or DEFAULT_LANG
    keyboard = [[InlineKeyboardButton("English" if lang == "ru" else "–†—É—Å—Å–∫–∏–π", callback_data=f"extra_toggle:{lang}")]]
    await update.message.reply_text(EXTRA_MESSAGES[lang], reply_markup=InlineKeyboardMarkup(keyboard), disable_web_page_preview=True)

async def handle_extra_toggle(update: Update, context: CallbackContext):
    query = update.callback_query
    await query.answer()
    current_lang = query.data.split(':')[1]
    new_lang = 'en' if current_lang == 'ru' else 'ru'
    save_user_data(query.from_user.id, 'lang', new_lang)
    keyboard = [[InlineKeyboardButton("English" if new_lang == "ru" else "–†—É—Å—Å–∫–∏–π", callback_data=f"extra_toggle:{new_lang}")]]
    await query.edit_message_text(text=EXTRA_MESSAGES[new_lang], reply_markup=InlineKeyboardMarkup(keyboard), disable_web_page_preview=True)

def uniCoder(text):
    if not text: return text
    replacements = [("aa", "ƒÅ"), ("ii", "ƒ´"), ("uu", "≈´"), ('"n', "·πÖ"), ("~n", "√±"), (".t", "·π≠"), (".d", "·∏ç"), (".n", "·πá"), (".m", "·πÉ"), (".l", "·∏∑"), (".h", "·∏•")]
    for pattern, repl in replacements: text = text.replace(pattern, repl)
    return text

# === –ò–ù–õ–ê–ô–ù-–†–ï–ñ–ò–ú (—Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –≥–æ—Ä—è—á–µ–π –∫–Ω–æ–ø–∫–æ–π) ===
async def inline_query(update: Update, context: CallbackContext):
    query = update.inline_query.query.strip()
    user_id = update.inline_query.from_user.id
    interface_lang = get_user_lang(user_id) or DEFAULT_LANG
    share_lang = get_user_share_lang(user_id) or interface_lang
    
    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∫–Ω–æ–ø–∫–∞ ¬´–û—Ç–∫—Ä—ã—Ç—å –Ω–∞ dg...¬ª
    action_text = "–û—Ç–∫—Ä—ã—Ç—å –Ω–∞ üîéDhamma.gift Ru" if share_lang == "ru" else "Open on üîéDhamma.gift En"
    btn_text = f"üîé {action_text}: {query}" if query else f"üîé {action_text}"
    path = "ru/" if share_lang == "ru" else ""
    encoded_q = urllib.parse.quote_plus(query)
    final_url = f"https://f.dhamma.gift/{path}{'?p=-kn&q=' + encoded_q if query else ''}"
    
    hot_button = InlineQueryResultsButton(text=btn_text, web_app=WebAppInfo(url=final_url))

    results = []
    if query:
        suggestions = autocomplete(query, max_results=29)
        converted_text = uniCoder(query)
        results.append(InlineQueryResultArticle(
            id="user_input",
            title=f"‚úèÔ∏è Send: {converted_text}" if interface_lang == "en" else f"‚úèÔ∏è –û—Ç–ø—Ä–∞–≤–∏—Ç—å: {converted_text}",
            input_message_content=InputTextMessageContent(format_message_with_links(converted_text, converted_text, lang=share_lang), parse_mode="HTML", disable_web_page_preview=True),
            reply_markup=create_keyboard(converted_text, lang=share_lang, is_inline=True)
        ))
        for idx, word in enumerate(suggestions[:29]):
            results.append(InlineQueryResultArticle(
                id=f"dict_{idx}", title=word,
                input_message_content=InputTextMessageContent(format_message_with_links(word, word, lang=share_lang), parse_mode="HTML", disable_web_page_preview=True),
                reply_markup=create_keyboard(word, lang=share_lang, is_inline=True)
            ))
    
    await update.inline_query.answer(results, button=hot_button, cache_time=0, is_personal=True)

async def handle_message(update: Update, context: CallbackContext):
    if not update.message or not update.message.text: return
    text = update.message.text.strip()
    user = update.effective_user
    if update.message.via_bot and update.message.via_bot.username in ["dgift_bot", "dhammagift_bot", "cakkhu_bot"]: return
    if re.search(r'http[s]?://', text):
        lang = get_user_lang(user.id) or DEFAULT_LANG
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–∏—à–ª–∏—Ç–µ —Ç–µ–∫—Å—Ç –±–µ–∑ URL." if lang == "ru" else "Please send text without URLs.")
        return

    share_lang = get_user_share_lang(user.id)
    converted_text = uniCoder(text)
    await update.message.reply_text(format_message_with_links(converted_text, converted_text, lang=share_lang), reply_markup=create_keyboard(converted_text, lang=share_lang), parse_mode="HTML", disable_web_page_preview=True)

async def toggle_language(update: Update, context: CallbackContext):
    query = update.callback_query
    await query.answer()
    parts = query.data.split(':')
    is_inline = parts[0] == 'inline_toggle_lang'
    new_lang = 'ru' if parts[1] == 'en' else 'en'
    search_query = ':'.join(parts[2:])
    save_user_data(query.from_user.id, 'share_lang', new_lang)
    save_user_data(query.from_user.id, 'lang', new_lang)
    await query.edit_message_text(text=format_message_with_links(search_query, search_query, lang=new_lang), reply_markup=create_keyboard(search_query, lang=new_lang, is_inline=is_inline), parse_mode="HTML", disable_web_page_preview=True)

def main():
    os.makedirs("assets", exist_ok=True)
    app = Application.builder().token(TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CallbackQueryHandler(handle_language_selection, pattern="^lang_set:"))
    app.add_handler(InlineQueryHandler(inline_query))
    app.add_handler(CommandHandler("extra", extra_command))
    app.add_handler(CallbackQueryHandler(handle_extra_toggle, pattern=r"^extra_toggle:"))  
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(CallbackQueryHandler(toggle_language, pattern=r"^(inline_)?toggle_lang:"))
    app.run_polling()

if __name__ == "__main__":
    main()
